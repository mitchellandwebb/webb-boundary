
We are wanting to write DSL code for the boundary as follows:

A boundary is defined as 

```
boundary Name where
  function1 :: Int -> Number -> Effect String
  function2 :: Name -> Nullable Height -> Aff Example
```

Type names will always be capitalized. keywords and function names will be entirely in lowercase. To specify whether the bound is syncronous or asyncronous, the final type of a boundary function must be labeled 'Effect' or 'Aff' to signal the intent -- whether the boundary is expected to be blocking to the calling thread or not.

Within a boundary's function, all types should be named. Names can be primitives like Int, Number, Double, Boolean, and String. A type can also be made nullable -- that is, possibly not present -- with a Nullable label. That is the extent of the primitive types. 

Several complex types can be defined, as shown below. The `Array` and `Tuple` types
are predefined and just need type arguments, but to use labeled tuples (records), a 
type alias must be defined, as in `Example` below. This gives us a proper name that we can use in the generated output code, so that the target language can reference this type without needing to determine a name.

```
boundary Name where
  function1 :: Array Int -> Tuple String Int -> Effect Unit
  
type Example = { name :: String, age :: Int }
type Path = String
```

As in the example above, the `type` keyword also allows us to alias existing types to improve readability. If the target language supports aliases, the alias will be preserved; otherwise, the final aliased type will be used.

Just as multiple type aliases can be specified in one file, multiple _boundaries_ can
also be specified in one file. Thus we can have 

```
boundary Person where
  function1 :: Array Int -> Tuple String Int -> Effect Unit
  
boundary Person2 where
  function1 :: Int -> String -> Aff Unit
``` 

Since the boundaries have different names, the function names are allowed to be the same. It is up to code generation to determine how to handle this in the output language, to determine whether this would cause trouble, and to write the output files correctly so that there's no issue.

We also might have _multiple_ boundary files. We don't want that kind of complication. Each boundary file is compiled separately, thank you very much, and does not rely on imports from anywhere else. We'll keep this simple and useful.


----------------------------------------------

Okay. We now have the parse tree as a pure data structure. There's ... both
good and bad in that. We cannot easily modify the tree in this form. On the other
hand, it's well-typed and provides a clear way of extracting information about
what we have, with a visitor that can at least _try_ to visit items consistently.

But okay. We have this initial data structure, and reason to allow it to be stable. What next? What is it that we want to do with it? Well, first we want to validate a few things. 

- We want to build an initial symbol table. We want to know what symbols are already declared and defined in the global scope (the only scope we have, here)
- We want to use the symbol table to check that all symbols are actually _defined_. In our case, there's only the global scope, so that's easy-enough to check, but if we had lexical scopes, we'd want to go into each scope and _build on_ the global lexical scope over time as we go deeper into each lexical scope, to see whether all symbols are defined in each scope.
- We want to use the symbol table to generate knowledge of each symbol's _type_. We might not have all this information initially, but we need to build it up, gradually. In this process, we may need to verify type _completeness_ -- for example, an (Array Array) is no good because the second Array is not a complete type, but an (Array (Array Int)) would be sufficient. This process is thus recursive. We don't necessarily know the dependency order of all types. So we make a best guess and, when we encounter a type within the file, if it depends on other symbols, we type those symbols first. This is an informal graph -- so if we depend on another type, circularly, we detect
that we've visited this type before and err with a circular type.
- Once we've checked that all types are complete, we can output the types, ideally in the same order they appear in the file. We'll output it to a single target file, converting it to the right structure in the target language.

One interesting point, though, is circular types -- or rather, recursive types. How can a type ultimately refer to itself? What does that require? The problem is that when a type refers to itself is it well-typed? Well, that depends. In a simple type like a Record -- _no_ . The type is recursive and thus cannot terminate. Although it is _typable_, it is not constructable except by recursive loop. If the type has _alternatives_ that might terminate, then it is possible. But in theory, nothing is 
wrong with recursive types -- it is, in theory, a valid, terminated type that will simply be impossible to construct at runtime. This differs between Purescript and Kot Kotlin of the implicit _pure references_, and also whether a value is _required_ at runtime -- but it's certainly true that we can obtain subtle construction bugs as a result. Preventing the bare circular type does prevent recursion in a bunch of cases, but naturally, not all.

------------------------------

Okay. So we have the ability to construct the symbol table, and to check the boundaries and their functions for correctness against the existing symbols and their types. So ... now what? How do we go about generating final files? And do we 
even want to do the generation here? What would make the generation pleasant, and how do we know what to generate? How much distance is there from the Tree, or from a Symbol Table, or whatever, to the file that we want to generate? And in what steps should we try to bridge that distance?

It would seem the parse tree itself ... is not sufficient. Type aliases aren't a great way for us to figure what needs to go where. But there is a 1-1 correspondence between alias and construct in most languages. So ... maybe?

After all, what did type-checking accomplish? It told us that the structure of the parse tree also correctly represents intent. But what is the intent that we actually
want to write?

data types
interface types using the data types, expressed in the form of the language.

So we need the types that need to be written, in declaration order, so we can write
systematically. And we need them in a form that is _interpretable_. Aliases may be Int,
Double -- primitives that are easy to convert by looking up the target type in the target
language. But aliases may also be product types or records. Since circularity is not allowed,
we should observe a clear declaration path. We _should_. But when we see product types, how
do we map these to target types in the target language? And ... the symbol table does
specify how symbols refer to each other. But it doesn't really store the target 
type itself; if I say `type A = List Int` and `type B = Map Int Int`, the symbol 
table understands that B is an alias ... but it doesn't understand what _type_ of
alias it is. It doesn't have that data; it doesn't store its actual definition data; and
it ... doesn't necessarily need to, here. So indeed ... what data is actually needed? What
actually ... _is_ an alias?
  An alias refers to a complete type. An alias can use _other_ aliases. Thus, an alias
is a symbol characterized by its complete parameter, NOT any particular single name. Thus,
it is a symbol to _multiple_ other symbols -- one for each parameter within it. In the end, the correctness of an alias is not determined by the alias itself -- if we were doing type _matching_, then yes, an alias would need to look up the other type by itself -- ALL of the other type -- to derive a concrete fully-reduced parameter. But in terms of the alias referring to a valid symbol -- that is unneeded. Parameters can be validated on their own against the symbol table in this case.
  But in the end, there's a funny difference in the symbol table. Aliases refer to
concrete types with the type symbols. But other symbols refer to single symbols on their
own, that map to type-ish definitions. Thus, an Alias like `Array Int` refers to an Int,
while `Array` refers to a `Product 1` -- it does not itself have a complete type, but 
maintains a record of how it is valid to use this symbol, as a higher-kinded type. This
is useful for type-checking. But what we want when writing code like this is _not_ every
incomplete type, which cannot have a concrete representation (at least in our case) at
runtime, but the complete types.
  Even though we _say_ aliases, we really are declaring a type that needs representation. And since it has a path through the symbol table, it's useful -- it's part of how we traverse the
relation of symbols to other symbols quickly, until we bottom out at _base_ symbols and
the information that is part of them. And so that's ... fairly odd, actually. Because we 
don't want the base symbols. We don't want to follow anything anywhere; we don't care if
something is a Product or an Alias or whatever, when we're trying to compile it. What we 
really want is just to look at the Aliases as they really are -- A Name associated with
other names -- and ensure these find their way into the output. An `Array Int`? A
`Map String String`? A `Boolean`? These all find standard definitions and ways of operating
in the target language compiler, and can have access to the SymbolTable if that's useful,
but otherwise it should be enough to write a alias with a name and a construction of the 
output type. 
  But is it actually enough? No, it's not. After all, we might see an `Array (Array Int)`. That's far more than a simple string. So we have the alias an its parameter, and it is
this data that needs to be transformed into the target language. No further processing is 
needed; this is a perfect representation of our knowledge about the alias, when paired
with the Symbol table.
  What we care about with aliases is ensuring that they are, or can be, defined in the right order. They don't have to be; many languages don't care, but some do, like Clojure (if we assume a Typed Clojure). So we need to start with an Array of aliases in the order presented 
in the original file, but provide a _sort_ function for the array, if the target language
desires to sort.
  Similarly, we need to handle Boundaries. Typically we place these _after_ the aliases,
so that all types using them will definitely be declared, and since boundaries themselves
are not actual types that can be used in other types. But how do we represent them? Well, they're already well-represented enough in the boundary table, even if they're out-of-order. But we don't need them to be in lookup tables -- we just need arrays of the data that we
can iterate over simply, along with the names. So there's nothing special needed there.

If we want to compile the Boundary and Alias declarations into Kotlin, we can try, but we lack certain kinds of knowledge. In particular, we lack knowledge of the language. What _is_ Kotlin? What constructs are we interested in? And what does it mean to work with them? With Kotlin, we are interested in a few different things. First, we're interested in the representation of a Boundary as a Kotlin Interface. What does it mean to do so? Well, the
interface has:

- Name
- IsAsync
- Function*
  - Name
  - Arg*
    - Type*
  - Return
    - Type*
    
This is ... fairly easy, for most of it, to transform a Boundary into a Kotlin Interface data structure. The hard part is the `Type*`. This could be one of ... many things. But in terms of _data_ -- what Kotlin thinks it is -- it's quite simple. It's a 

```
{ name :: String, args :: Array String }
```

Surprisingly, that's all that's needed! A primary type name, and any type arguments that
are applied. Thus, an `Array Int` becomes a Kotlin `{ name: "List", args: [ Int ]}`, which
is written to file as `List<Int>`. Yet it's not that simple. Type arguments can be recursive, and so we have a Kotlin version of Param:

```
{ name :: String, args :: Array Param }
```

This recursive parameter can thus become a nested printout of a filled generic type. The next question is how we ultimately _transform_ the Params into Kotlin Params, but we'll table that discussion until after we know what Aliases are -- since Aliases will also need the answer to that question.

So for aliases, we have a name, and a concrete type. But not always. Sometimes the concrete type is really just a Param. In which case we go back to the discussion above. But it might also be a Record Map. In that case, we need to define a _Data Class_; that is,

- Name 
  - Param*
    - Name
    - Type*
    
That's it! Something is recursive about it. But the type itself might include Aliases ... so what really matters is that we can convert _any_ Param into the Kotlin type -- just the correct strings.

So how do we convert it? Well, we just start with our normal Param, and convert it to the KotlinParam. But to get the _actual_ type for Kotlin, we need the concept of Kotlin symbol lookup -- where each formal Symbol we have can find a lookup as a Kotlin type. We need ways to _ask questions_ ... but to ask them in a general way; to ask them in conceptual forms. Thus, we need different kinds of knowledge -- the Env, and a lookup table from simple strings from our application to Kotlin strings for OOB types. This is NOT the same as as aliases -- just the ability to transform Params to KotlinParams.

Okay. So now we can transform each of the "Kotlin" Params into a String. But the thing is ... they don't seem particularly like kotlin-specific parameters, or methods, or interfaces. They seem very-generalized representations of the final types in abstract form, and can be translated into any language. So there's no reason to keep them as they are. Instead, they each represent a generalized concept of a type -- an Interface, Method, Record, or Type parameter. And these are all we need to write them out; this intermediate representation is easy to convert to the target languages we're interested in. 
  But that means we have to answer the question of how each node of the Parse tree becomes the generalized form. And that varies by the _converter_ that is used. The converter is thus a unique type that specifically knows how to convert a _Param_ into a generalized param, since what needs replacing are the types used by the target language -- and that's all. It's more of a ... type-replacer, than anything else. After that, the conversion of each Generalized structure is defined per-structure for each language. Thus, our definition of each language defines a way to convert a Param to a GParam, and a way to turn each GStructure into a String (they rely on each other). And each GStructure defines, on its own, how to obtain itself from a Converter data structure, which is generalized and initialized from a language definition.

TODO -- tokenizing. TypeName and FunctionName are last ... but they also match the keywords.
So ... will that work out? Or do they have to be merged?